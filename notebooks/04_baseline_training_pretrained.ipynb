{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eadeb9e0",
   "metadata": {},
   "source": [
    "### Baseline Training\n",
    "\n",
    "Here we'll use the pretrained resnet model without an augmentation with limited data.\n",
    "\n",
    "This will help to the planning of the further stages of the model development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff512c61",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "from src import utils\n",
    "from src.data.datasets import CloudHoleDataset\n",
    "from src.models.models import CNN_Model\n",
    "from src.training.train import (\n",
    "    train_model,\n",
    "    test\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('Greys_r')\n",
    "\n",
    "labels_path = f\"{os.getenv('processed_data_path')}/labels_revised.csv\"\n",
    "gold_data_path = f\"{os.getenv('gold_data_path')}/seviri/\"\n",
    "model_save_path = f\"{os.getenv('model_save_path')}/pretrained_baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "LOGS_PATH = 'logs/v1.0_baseline'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "NUM_WORKERS = 4\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e982fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded GoldCloudHoleDataset\n",
      "  Path: /home/plato/dl_cloudhole/dl_cloudhole/data/processed/gold/seviri//v1.0_baseline/train/data.zarr\n",
      "  Samples: 165\n",
      "  Augmentation: OFF\n",
      "  Normalization: mean=13.0594, std=7.281753233658452\n",
      "✓ Loaded GoldCloudHoleDataset\n",
      "  Path: /home/plato/dl_cloudhole/dl_cloudhole/data/processed/gold/seviri//v1.0_baseline/validation/data.zarr\n",
      "  Samples: 131\n",
      "  Augmentation: OFF\n",
      "✓ Loaded GoldCloudHoleDataset\n",
      "  Path: /home/plato/dl_cloudhole/dl_cloudhole/data/processed/gold/seviri//v1.0_baseline/test/data.zarr\n",
      "  Samples: 98\n",
      "  Augmentation: OFF\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CloudHoleDataset(\n",
    "    gold_zarr_path=f\"{gold_data_path}/v1.0_baseline/train/data.zarr\",\n",
    "    augment=False,\n",
    "    pretrained=True,\n",
    "    model='resnet18'\n",
    ")\n",
    "\n",
    "validation_dataset = CloudHoleDataset(\n",
    "    gold_zarr_path=f\"{gold_data_path}/v1.0_baseline/validation/data.zarr\",\n",
    "    augment=False,\n",
    "    pretrained=True,\n",
    "    model='resnet18'\n",
    ")\n",
    "\n",
    "test_dataset = CloudHoleDataset(\n",
    "    gold_zarr_path=f\"{gold_data_path}/v1.0_baseline/test/data.zarr\",\n",
    "    augment=False,\n",
    "    pretrained=True,\n",
    "    model='resnet18'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLOUD HOLE DETECTION - TRAINING\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plato/.virtualenvs/dlcloudhole/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/plato/.virtualenvs/dlcloudhole/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Freezing backbone layers...\n",
      "✓ Backbone frozen\n",
      "✓ Classification head (fc layer) unfrozen and ready to train\n",
      "\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 1,026\n",
      "Frozen parameters: 11,176,512\n",
      "Trainable ratio: 0.01%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n' + '='*80)\n",
    "print('CLOUD HOLE DETECTION - TRAINING')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "# Create directories\n",
    "Path(model_save_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(LOGS_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# FREEZE ALL LAYERS\n",
    "print('\\nFreezing backbone layers...')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# UNFREEZE ONLY THE CLASSIFICATION HEAD\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # Binary classification\n",
    "\n",
    "# The new fc layer is unfrozen by default\n",
    "\n",
    "print(f'✓ Backbone frozen')\n",
    "print(f'✓ Classification head (fc layer) unfrozen and ready to train\\n')\n",
    "\n",
    "\n",
    "# VERIFY WHICH LAYERS ARE TRAINABLE\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')\n",
    "print(f'Frozen parameters: {total_params - trainable_params:,}')\n",
    "print(f'Trainable ratio: {trainable_params/total_params*100:.2f}%\\n')\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# OPTIMIZER - ONLY UPDATE TRAINABLE PARAMETERS\n",
    "# Option 1: Only pass trainable parameters (more efficient)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f386084",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    min_delta=MIN_DELTA,\n",
    "    save_dir=model_save_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best model for testing...\n",
      "✓ Loaded best model from epoch 20\n",
      "\n",
      "================================================================================\n",
      "TESTING MODEL\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 2/2 [00:21<00:00, 10.64s/it, loss=0.4553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST RESULTS\n",
      "================================================================================\n",
      "Loss:        0.4553\n",
      "Accuracy:    0.7551\n",
      "Precision:   0.8246\n",
      "Recall:      0.7705\n",
      "Specificity: 0.7297\n",
      "F1 Score:    0.7966\n",
      "ROC-AUC:     0.8653\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "                 0      1\n",
      "Actual  0       27    10\n",
      "        1       14    47\n",
      "================================================================================\n",
      "\n",
      "✓ Test results saved to: logs/v1.0_baseline/test_results.json\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "Best model: /home/plato/dl_cloudhole/dl_cloudhole/models/pretrained_baseline/best_model.pth\n",
      "Test results: logs/v1.0_baseline/test_results.json\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading best model for testing...')\n",
    "\n",
    "checkpoint = torch.load(Path(model_save_path) / 'best_model.pth', weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f'✓ Loaded best model from epoch {checkpoint[\"epoch\"]+1}')\n",
    "\n",
    "test_metrics = test(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    save_path=Path(LOGS_PATH) / 'test_results.json'\n",
    ")\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*80)\n",
    "print(f'Best model: {model_save_path}/best_model.pth')\n",
    "print(f'Test results: {LOGS_PATH}/test_results.json')\n",
    "print('='*80 + '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
