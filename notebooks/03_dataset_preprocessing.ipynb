{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc576ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.utils import (\n",
    "    NetCDFToZarrConverter\n",
    ")\n",
    "raw_data_path = \"../data/raw/seviri\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 17:11:29,427 - INFO - Analyzing NetCDF files matching: ../data/raw/seviri/hrv_lr2*.nc\n",
      "2026-01-29 17:11:29,431 - INFO - Found 56 files\n",
      "/home/plato/dl_cloudhole/dl_cloudhole/src/utils.py:74: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  dims = dict(ds.dims)\n",
      "2026-01-29 17:11:31,083 - INFO - Calculated chunk size: 19.97 MB | chunks={'time': 261, 'y': 92, 'x': 109}\n",
      "2026-01-29 17:11:31,084 - INFO - Analysis complete: {'num_files': 56, 'files': ['hrv_lr200401.nc', 'hrv_lr200411.nc', 'hrv_lr200412.nc', 'hrv_lr200501.nc', 'hrv_lr200511.nc', 'hrv_lr200512.nc', 'hrv_lr200601.nc', 'hrv_lr200611.nc', 'hrv_lr200612.nc', 'hrv_lr200701.nc', 'hrv_lr200711.nc', 'hrv_lr200712.nc', 'hrv_lr200801.nc', 'hrv_lr200811.nc', 'hrv_lr200812.nc', 'hrv_lr200901.nc', 'hrv_lr200911.nc', 'hrv_lr200912.nc', 'hrv_lr201001.nc', 'hrv_lr201011.nc', 'hrv_lr201012.nc', 'hrv_lr201101.nc', 'hrv_lr201111.nc', 'hrv_lr201112.nc', 'hrv_lr201201.nc', 'hrv_lr201202.nc', 'hrv_lr201211.nc', 'hrv_lr201212.nc', 'hrv_lr201301.nc', 'hrv_lr201302.nc', 'hrv_lr201311.nc', 'hrv_lr201312.nc', 'hrv_lr201401.nc', 'hrv_lr201402.nc', 'hrv_lr201411.nc', 'hrv_lr201412.nc', 'hrv_lr201501.nc', 'hrv_lr201502.nc', 'hrv_lr201511.nc', 'hrv_lr201512.nc', 'hrv_lr201601.nc', 'hrv_lr201602.nc', 'hrv_lr201611.nc', 'hrv_lr201612.nc', 'hrv_lr201701.nc', 'hrv_lr201702.nc', 'hrv_lr201711.nc', 'hrv_lr201712.nc', 'hrv_lr201801.nc', 'hrv_lr201802.nc', 'hrv_lr201811.nc', 'hrv_lr201812.nc', 'hrv_lr201901.nc', 'hrv_lr201902.nc', 'hrv_lr201911.nc', 'hrv_lr201912.nc'], 'dimensions': {'time': 52928, 'y': 92, 'x': 109}, 'variables': ['hrv'], 'coordinates': ['lat', 'lon', 'time'], 'dtype_size': 8, 'recommended_chunks': {'time': 261, 'y': 92, 'x': 109}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 261, 'y': 92, 'x': 109}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scaling only performed for time dimension \n",
    "# 20MB per chunk is aimed\n",
    "\n",
    "converter = NetCDFToZarrConverter()\n",
    "\n",
    "chunk_analysis = converter.analyze_netcdf_files(\"../data/raw/seviri/hrv_lr2*.nc\")\n",
    "\n",
    "chunk_analysis[\"recommended_chunks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "input_file_pattern=\"../data/raw/seviri/hrv_lr2*.nc\"\n",
    "\n",
    "files = sorted(Path().glob(input_file_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 17:07:18,625 - INFO - Converting multiple files to single Zarr: ../data/raw/seviri/hrv_lr2*.nc\n",
      "2026-01-29 17:07:18,628 - INFO - Found 56 files to convert\n",
      "2026-01-29 17:07:19,775 - INFO - Writing consolidated Zarr with chunks: {'time': 261, 'y': 92, 'x': 109}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.955028712749481 GB dataset\n",
      "Frozen({'time': (261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 206), 'y': (92,), 'x': (109,)})\n",
      "[########################################] | 100% Completed | 29.46 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 17:07:49,690 - INFO - Successfully created consolidated Zarr at ../data/processed/seviri/hrv_lr2004_2019.zarr\n",
      "2026-01-29 17:07:49,692 - INFO - \n",
      "============================================================\n",
      "2026-01-29 17:07:49,692 - INFO - Zarr Store Information: ../data/processed/seviri/hrv_lr2004_2019.zarr\n",
      "2026-01-29 17:07:49,693 - INFO - ============================================================\n",
      "2026-01-29 17:07:49,694 - INFO - /\n",
      " ├── hrv (52928, 92, 109) float64\n",
      " ├── lat (92, 109) float64\n",
      " ├── lon (92, 109) float64\n",
      " └── time (52928,) int64\n",
      "2026-01-29 17:07:49,698 - INFO - ============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Issue:Segmentation fault (core dumped)\n",
    "- Reason: parallel=True, chunks='auto' on xr.open_mfdataset\n",
    "- Solution: set parallel false and chunks to None\n",
    "\"\"\"\n",
    "\n",
    "converter.convert_multiple_files_to_single_zarr(\n",
    "    file_pattern = input_file_pattern,\n",
    "    output_path = f\"../data/processed/seviri/hrv_lr{files[0].as_posix()[-9:-5]}_{files[-1].as_posix()[-9:-5]}.zarr\",\n",
    "    custom_chunks = chunk_analysis[\"recommended_chunks\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
